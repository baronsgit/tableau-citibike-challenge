{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import AppHelpers as ah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_data_path = Path(\"Data/JC-202001-citibike-tripdata.csv\")\n",
    "feb_data_path = Path(\"Data/JC-202002-citibike-tripdata.csv\")\n",
    "mar_data_path = Path(\"Data/JC-202003-citibike-tripdata.csv\")\n",
    "apr_data_path = Path(\"Data/JC-202004-citibike-tripdata.csv\")\n",
    "may_data_path = Path(\"Data/JC-202005-citibike-tripdata.csv\")\n",
    "\n",
    "jan_data = pd.read_csv(jan_data_path)\n",
    "feb_data = pd.read_csv(feb_data_path)\n",
    "mar_data = pd.read_csv(mar_data_path)\n",
    "apr_data = pd.read_csv(apr_data_path)\n",
    "may_data = pd.read_csv(may_data_path)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "stations_data = pd.concat([feb_data, mar_data, apr_data, may_data], ignore_index=True)\n",
    "\n",
    "# only keep the columns we need and ignore duplicates and reset index\n",
    "start_stations = stations_data[['start station id', 'start station name', 'start station latitude', 'start station longitude']].drop_duplicates().reset_index(drop=True)\n",
    "end_stations = stations_data[['end station id', 'end station name', 'end station latitude', 'end station longitude']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# rename columns\n",
    "start_stations = start_stations.rename(columns={'start station id': 'station_id', 'start station name': 'station_name', 'start station latitude': 'station_latitude', 'start station longitude': 'station_longitude'})\n",
    "end_stations = end_stations.rename(columns={'end station id': 'station_id', 'end station name': 'station_name', 'end station latitude': 'station_latitude', 'end station longitude': 'station_longitude'})\n",
    "\n",
    "# combine start and end stations and drop duplicates and reset index\n",
    "stations = pd.concat([start_stations, end_stations], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# add columns for city and zip code\n",
    "stations.insert(1, \"city\",\"\")\n",
    "stations.insert(2, \"zipcode\",\"\")\n",
    "\n",
    "# stations.head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the dataframe to include 10 rows\n",
    "# stations = stations.iloc[0:5]\n",
    "\n",
    "# write a loop to add city name and zip code to the dataframe using get_city_zip\n",
    "for index, row in stations.iterrows():\n",
    "    cityzip = ah.get_cityzipcode(row[\"station_latitude\"], row[\"station_longitude\"])\n",
    "    stations.loc[index, \"city\"] = cityzip[0]\n",
    "    stations.loc[index, \"zipcode\"] = cityzip[1]\n",
    "\n",
    "# stations.head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.to_csv(Path('Resources/citibike_stations.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
